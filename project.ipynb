{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project : Sentiments classification on movies review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "#load_files:Load text files with categories as subfolder names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_files('dataset/train',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am a huge John Denver fan. I have a large collection of his music on vinyl. I saw this Christmas special when it was originally on TV and loved it. I have the original vinyl album and CD. I have the original CD and later release. The later release is missing several songs though. I see that it has been released this year with all original songs. To my surprise I found the original CD for sale at $75.00. WOW - to think that a Christmas Cd would be worth that much. To me no amount is worth selling this treasure. It is my favorite Christmas CD. I have never been able to find it on VHS or DVD. I would love to have either version. If anyone has one available please let me know. Thanks'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(train.data)\n",
    "train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([500, 500], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.data\n",
    "y_train = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_files('dataset/test/',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.data\n",
    "y_test = test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I almost called HBO and demanded my money back for the month just because they\\'ve been airing this movie. I can just see the movie execs sitting around going, \"Okay, we need to come up with something that\\'s just like Home Alone, only we\\'ll add a bunch of cash for the kid, hire cut-rate actors, and oh yeah, we\\'ll make it a lot less funny!\"<br /><br />Okay, maybe not the last part, but that\\'s basically what you\\'ve got here. Not even worth seeing if someone else rents it. And as a movie for kids? Forget it. I wouldn\\'t let my kids see this, not necessarily because of bad-taste jokes, but because I wouldn\\'t want them to say, \"What were you thinking showing us that lame piece of garbage, Dad?!?!\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    #x=re.sub(r'\\W',' ',x)\n",
    "    #x = re.sub(r'[^a-zA-Z]',' ',x)\n",
    "    x = re.sub(\"wouldn\\'t\",'would not',x)\n",
    "    x = re.sub(\"they\\ 've\",'they have',x)\n",
    "    \n",
    "    #to remove html tags\n",
    "    x = re.sub(r'<.*?>', '', x)\n",
    "    \n",
    "    #to remove everything except alpha\n",
    "    x = re.sub(r'[^a-zA-Z]',' ',x)\n",
    "    \n",
    "      \n",
    "    x = re.sub(r'\\s+',' ',x)          #remove extra space's\n",
    "    return x.lower()\n",
    "    \n",
    "#\\W:matches any non-alphanumeric character; \n",
    "#this is equivalent to the set [^a-zA-Z0-9_]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i would not hello a hi john ok'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean('I wouldn\\'t hello  ..!  a 123#hi john <html> ok</html>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a huge John Denver fan. I have a large co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I just read the plot summary and it is the wor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I almost called HBO and demanded my money back...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Like his earlier film, \"In a Glass Cage\", Agus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are few films that leave me with the fee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  target\n",
       "0  I am a huge John Denver fan. I have a large co...       1\n",
       "1  I just read the plot summary and it is the wor...       1\n",
       "2  I almost called HBO and demanded my money back...       0\n",
       "3  Like his earlier film, \"In a Glass Cage\", Agus...       1\n",
       "4  There are few films that leave me with the fee...       1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_train,columns=['review'])\n",
    "df['target'] = y_train\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df.review.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am a huge john denver fan i have a large col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i just read the plot summary and it is the wor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i almost called hbo and demanded my money back...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like his earlier film in a glass cage agust vi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there are few films that leave me with the fee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  target\n",
       "0  i am a huge john denver fan i have a large col...       1\n",
       "1  i just read the plot summary and it is the wor...       1\n",
       "2  i almost called hbo and demanded my money back...       0\n",
       "3  like his earlier film in a glass cage agust vi...       1\n",
       "4  there are few films that leave me with the fee...       1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert text into numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'not' in words:\n",
    "    words.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv = CountVectorizer(min_df=10,max_df=.6,stop_words=words)\n",
    "cv = CountVectorizer(stop_words=words)\n",
    "\n",
    "#min_df=10:exclude any word that comes in 10 or less than 10 documents\n",
    "#max_df=.6:excude any word that comes more than 60% of the documents,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = cv.fit_transform(df.review.values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 15239)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaaarrgh',\n",
       " 'aachen',\n",
       " 'aapke',\n",
       " 'aaron',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandonment',\n",
       " 'abandons',\n",
       " 'abbas',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abducted',\n",
       " 'abductor',\n",
       " 'abe',\n",
       " 'abiding',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'abo',\n",
       " 'aboard',\n",
       " 'abominable',\n",
       " 'abominably',\n",
       " 'abomination',\n",
       " 'aboriginal',\n",
       " 'abortion',\n",
       " 'abound',\n",
       " 'aboutagirly',\n",
       " 'abracadabrantesque',\n",
       " 'abraham',\n",
       " 'abroad',\n",
       " 'abruptly',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absentminded',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorbs',\n",
       " 'absorption',\n",
       " 'abstain',\n",
       " 'abstract',\n",
       " 'abstraction',\n",
       " 'absurd',\n",
       " 'absurdism',\n",
       " 'absurdity',\n",
       " 'abu',\n",
       " 'abundance',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuses',\n",
       " 'abusive',\n",
       " 'abysmal',\n",
       " 'abysmally',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'accelerated',\n",
       " 'accent',\n",
       " 'accents',\n",
       " 'accentuates',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'accompanied',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplice',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishment',\n",
       " 'accorded',\n",
       " 'accordian',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accordion',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accounts',\n",
       " 'accumulated',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuses',\n",
       " 'ace',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'achilles',\n",
       " 'aching',\n",
       " 'achingly',\n",
       " 'achterbusch',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acidity',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquainted',\n",
       " 'acquart',\n",
       " 'acquired',\n",
       " 'acquitted',\n",
       " 'acres',\n",
       " 'acrobatic',\n",
       " 'acrobatics',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actioner',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'activism',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapted',\n",
       " 'adapting',\n",
       " 'adaption',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adele',\n",
       " 'adeptness',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adherence',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjoining',\n",
       " 'adjournment',\n",
       " 'adjuster',\n",
       " 'adjustin',\n",
       " 'administered',\n",
       " 'administration',\n",
       " 'administrator',\n",
       " 'admirable',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admiring',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'adobe',\n",
       " 'adolescent',\n",
       " 'adolescents',\n",
       " 'adolph',\n",
       " 'adopted',\n",
       " 'adoption',\n",
       " 'adopts',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adoree',\n",
       " 'adrian',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adulterous',\n",
       " 'adultery',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advances',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adversity',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advocacy',\n",
       " 'aesthetic',\n",
       " 'afar',\n",
       " 'affable',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affectations',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affects',\n",
       " 'afficinados',\n",
       " 'affirming',\n",
       " 'afford',\n",
       " 'afforded',\n",
       " 'affords',\n",
       " 'afi',\n",
       " 'aficionados',\n",
       " 'aforementioned',\n",
       " 'afoul',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'aftereffects',\n",
       " 'afterlife',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afterthought',\n",
       " 'afterwards',\n",
       " 'afterwords',\n",
       " 'aftra',\n",
       " 'agatha',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'ageing',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ager',\n",
       " 'ages',\n",
       " 'aggravating',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aghhh',\n",
       " 'agin',\n",
       " 'aging',\n",
       " 'agitated',\n",
       " 'agn',\n",
       " 'agnieszka',\n",
       " 'agniezska',\n",
       " 'agnisakshi',\n",
       " 'ago',\n",
       " 'agonizing',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'agust',\n",
       " 'agusti',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahlstedt',\n",
       " 'ahold',\n",
       " 'ahoy',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aided',\n",
       " 'aides',\n",
       " 'aids',\n",
       " 'aileen',\n",
       " 'ailing',\n",
       " 'ailments',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'air',\n",
       " 'aircraft',\n",
       " 'aired',\n",
       " 'airforce',\n",
       " 'airhead',\n",
       " 'airing',\n",
       " 'airline',\n",
       " 'airport',\n",
       " 'airs',\n",
       " 'aka',\n",
       " 'akelly',\n",
       " 'akin',\n",
       " 'akkaya',\n",
       " 'akosua',\n",
       " 'akward',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alamo',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alas',\n",
       " 'alba',\n",
       " 'albanian',\n",
       " 'albeit',\n",
       " 'alberson',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'albertson',\n",
       " 'album',\n",
       " 'alcantara',\n",
       " 'alcohol',\n",
       " 'alec',\n",
       " 'alecia',\n",
       " 'alegria',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandr',\n",
       " 'alexandre',\n",
       " 'alfre',\n",
       " 'alfred',\n",
       " 'alias',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'alienated',\n",
       " 'alienates',\n",
       " 'alienation',\n",
       " 'aliens',\n",
       " 'alike',\n",
       " 'aline',\n",
       " 'alisha',\n",
       " 'alison',\n",
       " 'alissia',\n",
       " 'alistair',\n",
       " 'alive',\n",
       " 'alkie',\n",
       " 'allan',\n",
       " 'alleged',\n",
       " 'allegorical',\n",
       " 'allegory',\n",
       " 'allen',\n",
       " 'alley',\n",
       " 'alliance',\n",
       " 'allied',\n",
       " 'allies',\n",
       " 'alligator',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allures',\n",
       " 'alluring',\n",
       " 'allusions',\n",
       " 'almodovar',\n",
       " 'almost',\n",
       " 'aloknath',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'aloof',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'aloung',\n",
       " 'aloy',\n",
       " 'alphabetti',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'altar',\n",
       " 'alter',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternates',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'altman',\n",
       " 'altogether',\n",
       " 'alun',\n",
       " 'alvin',\n",
       " 'always',\n",
       " 'alzheimer',\n",
       " 'amanda',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amateurishly',\n",
       " 'amati',\n",
       " 'amazed',\n",
       " 'amazes',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'amazonians',\n",
       " 'ambidexterous',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'ambivalence',\n",
       " 'amc',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'americans',\n",
       " 'amicus',\n",
       " 'amidst',\n",
       " 'amigo',\n",
       " 'amiss',\n",
       " 'amistad',\n",
       " 'amnesic',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amoral',\n",
       " 'amos',\n",
       " 'amount',\n",
       " 'amounts',\n",
       " 'ample',\n",
       " 'amplified',\n",
       " 'amrita',\n",
       " 'amsterdam',\n",
       " 'amulet',\n",
       " 'amuro',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'amusingly',\n",
       " 'anachronistic',\n",
       " 'anal',\n",
       " 'anally',\n",
       " 'analogies',\n",
       " 'analogy',\n",
       " 'analyse',\n",
       " 'analyses',\n",
       " 'analysis',\n",
       " 'analyze',\n",
       " 'anarchy',\n",
       " 'anatomical',\n",
       " 'anchor',\n",
       " 'anchored',\n",
       " 'ancient',\n",
       " 'ancillary',\n",
       " 'anderson',\n",
       " 'andersons',\n",
       " 'andie',\n",
       " 'andjudge',\n",
       " 'andre',\n",
       " 'andrei',\n",
       " 'andreu',\n",
       " 'andrew',\n",
       " 'andromantic',\n",
       " 'andy',\n",
       " 'anecdotal',\n",
       " 'anecdote',\n",
       " 'anesthetic',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angered',\n",
       " 'angle',\n",
       " 'angled',\n",
       " 'angles',\n",
       " 'anglo',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'anguishing',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'animatronics',\n",
       " 'anime',\n",
       " 'animosities',\n",
       " 'animosity',\n",
       " 'aninterview',\n",
       " 'ankle',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'annals',\n",
       " 'anne',\n",
       " 'annihilated',\n",
       " 'anniversary',\n",
       " 'announced',\n",
       " 'announces',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoyingly',\n",
       " 'annoys',\n",
       " 'annual',\n",
       " 'anomalies',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'ansonia',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answers',\n",
       " 'ant',\n",
       " 'antagonist',\n",
       " 'antarctica',\n",
       " 'antheil',\n",
       " 'anthology',\n",
       " 'anthony',\n",
       " 'anthropologist',\n",
       " 'anti',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'anticipation',\n",
       " 'antics',\n",
       " 'antiques',\n",
       " 'antithesis',\n",
       " 'antoine',\n",
       " 'antoinette',\n",
       " 'antoni',\n",
       " 'antonia',\n",
       " 'antonio',\n",
       " 'antonioni',\n",
       " 'anupam',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anxiously',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyoneactually',\n",
       " 'anyplace',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'ao',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apartments',\n",
       " 'ape',\n",
       " 'aplomb',\n",
       " 'apocalypse',\n",
       " 'apocalyptic',\n",
       " 'apollo',\n",
       " 'apologies',\n",
       " 'apologise',\n",
       " 'apologists',\n",
       " 'appaerantly',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'appallingly',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealed',\n",
       " 'appealing',\n",
       " 'appeals',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appearances',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'appease',\n",
       " 'appelation',\n",
       " 'appendix',\n",
       " 'appetit',\n",
       " 'applaud',\n",
       " 'applauded',\n",
       " 'applauding',\n",
       " 'applauds',\n",
       " 'applause',\n",
       " 'apple',\n",
       " 'apples',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appoach',\n",
       " 'appointed',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciating',\n",
       " 'appreciation',\n",
       " 'apprehension',\n",
       " 'apprentice',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approving',\n",
       " 'approx',\n",
       " 'approximately',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arabs',\n",
       " 'arbaaz',\n",
       " 'arbitrary',\n",
       " 'arbuthnot',\n",
       " 'archer',\n",
       " 'archery',\n",
       " 'architecture',\n",
       " 'archive',\n",
       " 'archives',\n",
       " 'archtypes',\n",
       " 'arcs',\n",
       " 'area',\n",
       " 'areall',\n",
       " 'areas',\n",
       " 'argento',\n",
       " 'argh',\n",
       " 'arguably',\n",
       " 'argue',\n",
       " 'argued',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'argumental',\n",
       " 'argumentative',\n",
       " 'arise',\n",
       " 'aristocratic',\n",
       " 'aristocrats',\n",
       " 'aristotelian',\n",
       " 'ark',\n",
       " 'arkansas',\n",
       " 'arm',\n",
       " 'armatures',\n",
       " 'armchair',\n",
       " 'armed',\n",
       " 'armena',\n",
       " 'arming',\n",
       " 'armor',\n",
       " 'armour',\n",
       " 'arms',\n",
       " 'armstrong',\n",
       " 'army',\n",
       " 'arnaz',\n",
       " 'arne',\n",
       " 'arness',\n",
       " 'arngrim',\n",
       " 'arnim',\n",
       " 'arnold',\n",
       " 'around',\n",
       " 'arousal',\n",
       " 'arouse',\n",
       " 'aroused',\n",
       " 'arouses',\n",
       " 'arousing',\n",
       " 'arquette',\n",
       " 'arranged',\n",
       " 'arrangement',\n",
       " 'arrant',\n",
       " 'array',\n",
       " 'arrested',\n",
       " 'arrivals',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogant',\n",
       " 'arrow',\n",
       " 'art',\n",
       " 'artemesia',\n",
       " 'artemisia',\n",
       " 'arthor',\n",
       " 'arthur',\n",
       " 'arthurian',\n",
       " 'articles',\n",
       " 'articulate',\n",
       " 'articulated',\n",
       " 'artifact',\n",
       " 'artifacts',\n",
       " 'artifice',\n",
       " 'artificial',\n",
       " 'artificiality',\n",
       " 'artificially',\n",
       " 'artillery',\n",
       " 'artimisia',\n",
       " 'artisanal',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'artistically',\n",
       " 'artistry',\n",
       " 'artists',\n",
       " 'arts',\n",
       " 'artwork',\n",
       " 'arty',\n",
       " 'ascript',\n",
       " 'ashamed',\n",
       " 'asher',\n",
       " 'ashes',\n",
       " 'ashley',\n",
       " 'ashore',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'asides',\n",
       " 'asinie',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'asmat',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'aspirations',\n",
       " 'aspire',\n",
       " 'aspires',\n",
       " 'aspiring',\n",
       " 'ass',\n",
       " 'assassin',\n",
       " 'assassinate',\n",
       " 'assassinated',\n",
       " 'assassination',\n",
       " 'assassins',\n",
       " 'assault',\n",
       " 'assaulted',\n",
       " 'assaulter',\n",
       " 'assed',\n",
       " 'assembled',\n",
       " 'assembly',\n",
       " 'assert',\n",
       " 'assertion',\n",
       " 'asset',\n",
       " 'assignment',\n",
       " 'assigns',\n",
       " 'assimilate',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'assists',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'associates',\n",
       " 'assorted',\n",
       " 'assortment',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assumes',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assured',\n",
       " 'assuredly',\n",
       " 'assures',\n",
       " 'astin',\n",
       " 'astonished',\n",
       " 'astonishing',\n",
       " 'astonishingly',\n",
       " 'astounding',\n",
       " 'astoundingly',\n",
       " 'astronishing',\n",
       " 'ate',\n",
       " 'athena',\n",
       " 'athey',\n",
       " 'athlete',\n",
       " 'athletic',\n",
       " 'atleast',\n",
       " 'atmosphere',\n",
       " 'atmospheres',\n",
       " 'atmospheric',\n",
       " 'atrocious',\n",
       " 'atrociously',\n",
       " 'atrocities',\n",
       " 'atrocity',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attacks',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attend',\n",
       " 'attended',\n",
       " 'attending',\n",
       " 'attends',\n",
       " 'attention',\n",
       " 'attentions',\n",
       " 'attilla',\n",
       " 'attire',\n",
       " 'attitiude',\n",
       " 'attitude',\n",
       " 'attitudes',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'attracted',\n",
       " 'attraction',\n",
       " 'attractions',\n",
       " 'attractive',\n",
       " 'attracts',\n",
       " 'attribute',\n",
       " 'attributed',\n",
       " 'attributes',\n",
       " 'attributing',\n",
       " 'attuned',\n",
       " 'atypical',\n",
       " 'auction',\n",
       " 'auctioned',\n",
       " 'aud',\n",
       " 'audacious',\n",
       " 'audience',\n",
       " 'audiences',\n",
       " 'audio',\n",
       " 'audiocassette',\n",
       " 'audiovisual',\n",
       " 'audition',\n",
       " 'auditioning',\n",
       " 'audrey',\n",
       " 'aughties',\n",
       " 'augmented',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'aura',\n",
       " 'auschwitz',\n",
       " 'aussie',\n",
       " 'aussies',\n",
       " 'austere',\n",
       " 'austrailia',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'australians',\n",
       " 'auteur',\n",
       " 'authentic',\n",
       " 'authentically',\n",
       " 'authenticity',\n",
       " 'author',\n",
       " 'authorial',\n",
       " 'authoritarian',\n",
       " 'authorities',\n",
       " 'authority',\n",
       " 'authors',\n",
       " 'autistic',\n",
       " 'auto',\n",
       " 'autobiographical',\n",
       " 'autobiography',\n",
       " 'autograph',\n",
       " 'autographs',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'automaticnc',\n",
       " 'automobiles',\n",
       " 'autumn',\n",
       " 'auzzie',\n",
       " 'avail',\n",
       " 'available',\n",
       " 'avalon',\n",
       " 'avant',\n",
       " 'avante',\n",
       " 'avariciously',\n",
       " 'avenge',\n",
       " 'avenging',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'averagely',\n",
       " 'avery',\n",
       " 'avid',\n",
       " 'avignon',\n",
       " 'avoid',\n",
       " 'avoided',\n",
       " 'awaited',\n",
       " 'awaiting',\n",
       " 'awake',\n",
       " 'awakened',\n",
       " 'awakening',\n",
       " 'awakens',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'awards',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'awol',\n",
       " 'ax',\n",
       " 'axe',\n",
       " 'azjazz',\n",
       " 'azteca',\n",
       " 'baaad',\n",
       " 'baad',\n",
       " 'babe',\n",
       " 'babes',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'bacchus',\n",
       " 'bach',\n",
       " 'back',\n",
       " 'backbone',\n",
       " 'backdrop',\n",
       " 'backdrops',\n",
       " 'backed',\n",
       " 'backer',\n",
       " 'backflashes',\n",
       " 'background',\n",
       " 'backgrounds',\n",
       " 'backing',\n",
       " 'backs',\n",
       " 'backseat',\n",
       " 'backstabber',\n",
       " 'backstabbing',\n",
       " 'backstage',\n",
       " 'backward',\n",
       " 'backwards',\n",
       " 'backyard',\n",
       " 'bacon',\n",
       " 'bacons',\n",
       " 'bacula',\n",
       " 'bad',\n",
       " 'badass',\n",
       " 'baddddd',\n",
       " 'baddie',\n",
       " 'baddies',\n",
       " 'badjatya',\n",
       " 'badjatyas',\n",
       " 'badly',\n",
       " 'baffled',\n",
       " 'baffling',\n",
       " 'bafta',\n",
       " 'bag',\n",
       " 'bags',\n",
       " 'bail',\n",
       " 'baio',\n",
       " 'bait',\n",
       " 'baiting',\n",
       " 'bajillion',\n",
       " 'baker',\n",
       " 'bakery',\n",
       " 'bakewell',\n",
       " 'bakula',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'bald',\n",
       " 'balder',\n",
       " 'baldly',\n",
       " 'baldwin',\n",
       " 'balearic',\n",
       " 'bales',\n",
       " 'ball',\n",
       " 'ballarat',\n",
       " 'balled',\n",
       " 'ballistic',\n",
       " 'balloon',\n",
       " 'ballroom',\n",
       " 'balls',\n",
       " 'ballz',\n",
       " 'baloney',\n",
       " 'balsa',\n",
       " 'bamboozled',\n",
       " 'banal',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'banderas',\n",
       " 'bandit',\n",
       " 'bands',\n",
       " 'bandwagon',\n",
       " 'bane',\n",
       " 'banging',\n",
       " 'bangs',\n",
       " 'bank',\n",
       " 'banker',\n",
       " 'bankrobbers',\n",
       " 'bankrupt',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use tfidf vectorizor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_new,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.983"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_new,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(X_test,columns=['review'])\n",
    "df_test['target'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Formulaic slasher film, only this one stars th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes, I am a romantic of sorts who likes musica...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I went to an advance screening of this movie t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Four things intrigued me as to this film - fir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our family (and the entire sold out sneak prev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  target\n",
       "0  Formulaic slasher film, only this one stars th...       0\n",
       "1  Yes, I am a romantic of sorts who likes musica...       1\n",
       "2  I went to an advance screening of this movie t...       1\n",
       "3  Four things intrigued me as to this film - fir...       0\n",
       "4  Our family (and the entire sold out sneak prev...       1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['review'] = df_test.review.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = cv.transform(df_test.review.values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 15239)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.785"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_test_new,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[\"I do not like this movie\",\n",
    "      \"I would not recommend this movie\",\n",
    "     \"I hate this movie\",\n",
    "      \"I love this movie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=[]\n",
    "for i in test:\n",
    "    s=clean(i)\n",
    "    f.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i do not like this movie',\n",
       " 'i would not recommend this movie',\n",
       " 'i hate this movie',\n",
       " 'i love this movie']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=cv.transform(f).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 15239)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets work on 50000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movie_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is one of those unfortunate films that su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Okay maybe it was because I happen to be in Ya...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although I love this movie, I can barely watch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man arrives in a strange, beautiful, sterile...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm sitting around going through movie listing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  This is one of those unfortunate films that su...          1\n",
       "1  Okay maybe it was because I happen to be in Ya...          1\n",
       "2  Although I love this movie, I can barely watch...          1\n",
       "3  A man arrives in a strange, beautiful, sterile...          1\n",
       "4  I'm sitting around going through movie listing...          1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25000\n",
       "0    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df.review.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(df.review.values,\n",
    "                                                 df.sentiment.values,\n",
    "                                                test_size=10000,\n",
    "                                                random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4962, 5038], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = CountVectorizer(stop_words=words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_new=cv1.fit_transform(x_train).toarray()\n",
    "#x_test_new = cv1.transform(x_test).toarray()\n",
    "\n",
    "x_new=cv1.fit_transform(x_train)\n",
    "x_test_new = cv1.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 92358)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 92358)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x_new,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.862"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(x_test_new,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i do not like this movie',\n",
       " 'i would not recommend this movie',\n",
       " 'i hate this movie',\n",
       " 'i love this movie']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=cv1.transform(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 92358)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nb_model.pkl','wb') as f1:\n",
    "    pickle.dump(nb,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save the vectorizer\n",
    "with open('cv1.pkl','wb') as f1:\n",
    "    pickle.dump(cv1,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nb_model.pkl','rb') as f1:\n",
    "    clf=pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
